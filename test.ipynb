{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 2장 파이토치 기본.pdf\n",
    "import torch\n",
    "\n",
    "print(torch.tensor([1,2,3,4,5]))\n",
    "print(torch.tensor([[1,2,3],[4,5,6]], dtype=torch.int64))\n",
    "print(torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 0],\n",
      "        [0, 1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "ft=torch.FloatTensor([[1,2,3],[4,5,6]]);print(ft)\n",
    "lt=torch.LongTensor([[1,2,3],[4,5,6]]);print(lt)\n",
    "bt=torch.ByteTensor([[1,0],[0,1]]);print(bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]] <class 'numpy.ndarray'> (2, 3)\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32) <class 'torch.Tensor'> torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array([[1,2,3],[4,5,6]])\n",
    "print(x,type(x), x.shape)\n",
    "\n",
    "tx=torch.from_numpy(x)\n",
    "print(tx, type(tx), tx.shape, tx.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]] <class 'numpy.ndarray'> (2, 3)\n"
     ]
    }
   ],
   "source": [
    "nx=tx.numpy()\n",
    "print(nx, type(nx), nx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1, 0],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(ft.long())\n",
    "print(lt.float())\n",
    "print(bt.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "torch.Size([3, 2, 2])\n",
      "x.dim 3\n",
      "len(x.size()) 3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([[[1,2],[3,4]], [[5,6],[7,8]], [[9,10],[11,12]]])\n",
    "\n",
    "print(x.shape)\n",
    "print(x.size())\n",
    "# x의 차원계수\n",
    "print('x.dim',x.dim())\n",
    "# x의 사이즈 len\n",
    "print('len(x.size())',len(x.size()))\n",
    "print(x.size(0))\n",
    "print(x.shape[0])\n",
    "print(x.size(1))\n",
    "print(x.shape[1])\n",
    "print(x.size(2))\n",
    "print(x.shape[2])\n",
    "# 마지막위치 -1(리버스)\n",
    "print(x.size(-1))\n",
    "print(x.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [6., 7.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 0.,  1.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.0000, 1.3333]])\n",
      "tensor([[0., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[False,  True],\n",
      "        [ True, False]])\n",
      "tensor([[ True, False],\n",
      "        [False,  True]])\n",
      "tensor([[ 1.,  4.],\n",
      "        [27., 64.]])\n"
     ]
    }
   ],
   "source": [
    "# 기본 연산(+ - * / == != ** )\n",
    "a=torch.FloatTensor([[1,2],[3,4]])\n",
    "b=torch.FloatTensor([[2,2],[3,3]])\n",
    "\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)\n",
    "print(a//b)\n",
    "print(a==b)\n",
    "print(a!=b)\n",
    "print(a**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "tensor([[2., 4.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a+1)\n",
    "print(a+torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a.mul_(b))  # 언더바 붙이면 밑에 a 값 변화 = 인플레이스 현상\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [3., 3.]])\n",
      "tensor(10.)\n",
      "tensor([5., 5.])\n",
      "tensor([4., 6.])\n",
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "# 인플레이스 연산(Inplace Operations)\n",
    "print(b)\n",
    "print(b.sum())\n",
    "print(b.sum(dim=0))\n",
    "print(b.sum(dim=-1))\n",
    "print(b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[ 7,  8],\n",
      "         [ 9, 10],\n",
      "         [11, 12]]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x=np.arange(1,13).reshape(3,2,2)\n",
    "# 3차원 tensor\n",
    "tx=torch.from_numpy(x)\n",
    "\n",
    "print(tx.view(3,4))\n",
    "print(tx.view(2,3,2))\n",
    "# -1은 모양을 잘 모를때\n",
    "print(tx.view(3,-1))\n",
    "print(tx.view(-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4]],\n",
       "\n",
       "        [[ 5,  6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11, 12]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx=tx.view(3,1,4)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]], dtype=torch.int32)\n",
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[ 7,  8],\n",
      "         [ 9, 10],\n",
      "         [11, 12]]], dtype=torch.int32)\n",
      "torch.Size([3, 1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 4])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze()함수 : 차원의 크기가 1인 차원 제거\n",
    "# Unsqueeze()함수 : Squeeze() 반대 함수로 Unsqueeze()로 지정된 차원의 인덱스에 차원의 크기가 1인 차원 삽입\n",
    "x1=tx.view(3,1,4)\n",
    "x2=tx.view(2,3,1,2)\n",
    "# 차원제거\n",
    "print(x1.squeeze())\n",
    "print(x2.squeeze())\n",
    "\n",
    "print(x1.size())\n",
    "x1.unsqueeze_(1)\n",
    "x1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([3, 4], dtype=torch.int32)\n",
      "tensor([2, 4], dtype=torch.int32)\n",
      "tensor([[ 9, 10],\n",
      "        [11, 12]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 인덱싱 / 슬라이싱\n",
    "tx.size()\n",
    "\n",
    "# 3차원중 1번째 요소\n",
    "print(tx[0])\n",
    "# 3차원요소 1번째, 전부\n",
    "print(tx[0,:])\n",
    "\n",
    "print(tx[0,:,:])\n",
    "\n",
    "print(tx[0,1,:])\n",
    "\n",
    "print(tx[0,:,1])\n",
    "\n",
    "print(tx[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# split 함수()\n",
    "# 텐서 자르기 split\n",
    "\n",
    "# x=torch.FloatTensor(10,4)\n",
    "# x 정수화\n",
    "x=torch.arange(1,41).view(10,4)\n",
    "# 스플릿 크기 4 dim=0은 2차원인데 크기 4로 자른다\n",
    "splits=x.split(4,dim=0)\n",
    "for s in splits:\n",
    "  print(s.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "x1=torch.arange(1,41).view(4,10)\n",
    "x1\n",
    "\n",
    "splits1=x.split(3, dim=1)\n",
    "for s in splits1:\n",
    "  print(s.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# chunks() 함수\n",
    "chunks = x.chunk(3, dim=0)\n",
    "for c in chunks:\n",
    "  print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16],\n",
      "        [17, 18, 19, 20],\n",
      "        [21, 22, 23, 24],\n",
      "        [25, 26, 27, 28],\n",
      "        [29, 30, 31, 32],\n",
      "        [33, 34, 35, 36],\n",
      "        [37, 38, 39, 40]])\n",
      "tensor([[ 9, 10, 11, 12],\n",
      "        [ 5,  6,  7,  8]])\n"
     ]
    }
   ],
   "source": [
    "# Index_Select 함수\n",
    "indice=torch.LongTensor([2,1])\n",
    "y=x.index_select(dim=0, index=indice)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  2.,  2.],\n",
       "        [ 9., 12.,  3.,  3.]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate 함수(cat())\n",
    "c=torch.cat([a,b], dim=1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.,  4.],\n",
      "         [ 9., 12.]],\n",
      "\n",
      "        [[ 2.,  2.],\n",
      "         [ 3.,  3.]]])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# stack()함수\n",
    "d=torch.stack([a,b])\n",
    "print(d)\n",
    "print(d.size())\n",
    "print(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.,  4.]],\n",
      "\n",
      "        [[ 9., 12.]]])\n",
      "torch.Size([2, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.,  4.],\n",
       "         [ 2.,  4.],\n",
       "         [ 2.,  4.]],\n",
       "\n",
       "        [[ 9., 12.],\n",
       "         [ 9., 12.],\n",
       "         [ 9., 12.]]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=a.view(2,1,2)\n",
    "print(aa)\n",
    "print(aa.size())\n",
    "\n",
    "# Expand 함수: 차원의 크기가 1인 차원을 원하는 크기로 늘려 줌\n",
    "y=aa.expand(2,3,2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[54, 21],\n",
       "         [92, 32],\n",
       "         [52,  9],\n",
       "         [20, 96],\n",
       "         [ 2, 33]],\n",
       "\n",
       "        [[44, 90],\n",
       "         [49, 72],\n",
       "         [86, 41],\n",
       "         [64, 65],\n",
       "         [27, 14]],\n",
       "\n",
       "        [[28, 83],\n",
       "         [84, 47],\n",
       "         [63, 31],\n",
       "         [69, 78],\n",
       "         [71, 60]],\n",
       "\n",
       "        [[ 4, 58],\n",
       "         [12, 26],\n",
       "         [98,  1],\n",
       "         [89, 93],\n",
       "         [34, 13]],\n",
       "\n",
       "        [[40, 17],\n",
       "         [55,  5],\n",
       "         [11,  8],\n",
       "         [37, 46],\n",
       "         [39, 59]],\n",
       "\n",
       "        [[95, 15],\n",
       "         [ 6, 81],\n",
       "         [75, 97],\n",
       "         [85, 91],\n",
       "         [19, 22]],\n",
       "\n",
       "        [[25, 80],\n",
       "         [10, 45],\n",
       "         [76, 68],\n",
       "         [56, 16],\n",
       "         [18, 82]],\n",
       "\n",
       "        [[30, 70],\n",
       "         [24, 87],\n",
       "         [ 3, 29],\n",
       "         [57, 36],\n",
       "         [51, 38]],\n",
       "\n",
       "        [[23, 42],\n",
       "         [99, 73],\n",
       "         [53, 88],\n",
       "         [ 0, 74],\n",
       "         [62, 48]],\n",
       "\n",
       "        [[67, 61],\n",
       "         [50, 77],\n",
       "         [66, 43],\n",
       "         [94, 79],\n",
       "         [35,  7]]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Pernutation 함수\n",
    "# 함수 명 : randperm(n) : 1~ n-1 범위의 숫자를 n개 랜덤 수열 생성\n",
    "\n",
    "x=torch.randperm(100).view(-1,5,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[14,  7, 22],\n",
       "         [15, 17, 21],\n",
       "         [19, 26, 11]],\n",
       "\n",
       "        [[ 4, 10, 25],\n",
       "         [20, 24, 12],\n",
       "         [ 2, 16,  1]],\n",
       "\n",
       "        [[ 5, 13,  6],\n",
       "         [18,  8, 23],\n",
       "         [ 3,  0,  9]]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randperm(3**3).view(3,3,-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 1],\n",
      "        [2, 1, 1],\n",
      "        [1, 2, 2]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Argument Max 함수 : argmax(dim=n) (0:1차원, 1:2차원)\n",
    "# 맨 마지막 값이 제일 큰 거\n",
    "y=x.argmax(dim=-1)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[22, 14],\n",
      "         [21, 17],\n",
      "         [26, 19]],\n",
      "\n",
      "        [[25, 10],\n",
      "         [24, 20],\n",
      "         [16,  2]],\n",
      "\n",
      "        [[13,  6],\n",
      "         [23, 18],\n",
      "         [ 9,  3]]])\n",
      "torch.Size([3, 3, 2])\n",
      "tensor([[[2, 0],\n",
      "         [2, 1],\n",
      "         [1, 0]],\n",
      "\n",
      "        [[2, 1],\n",
      "         [1, 0],\n",
      "         [1, 0]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [2, 0],\n",
      "         [2, 0]]])\n",
      "torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Top-k 함수 : 가장 큰 k개 값과 index 반환\n",
    "values,indices=torch.topk(x, k=2, dim=-1)\n",
    "print(values)\n",
    "print(values.size())\n",
    "print(indices)\n",
    "print(indices.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[22, 14],\n",
      "         [21, 17],\n",
      "         [26, 19]],\n",
      "\n",
      "        [[25, 10],\n",
      "         [24, 20],\n",
      "         [16,  2]],\n",
      "\n",
      "        [[13,  6],\n",
      "         [23, 18],\n",
      "         [ 9,  3]]])\n",
      "tensor([[[2, 0],\n",
      "         [2, 1],\n",
      "         [1, 0]],\n",
      "\n",
      "        [[2, 1],\n",
      "         [1, 0],\n",
      "         [1, 0]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [2, 0],\n",
      "         [2, 0]]])\n",
      "torch.Size([3, 3, 2])\n",
      "tensor([[[ True, False,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[False, False,  True],\n",
      "         [ True,  True,  True],\n",
      "         [False,  True, False]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [ True, False,  True],\n",
      "         [False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "# Masked Fill 함수 : 텐서 내에 원하는 부분 값만 변경\n",
    "# 1차원에서 가장 큰 k개의 값과 index 반환\n",
    "value, indices=torch.topk(x,k=2,dim=-1)\n",
    "print(value)\n",
    "print(indices)\n",
    "print(indices.size())\n",
    "\n",
    "mask = x > 10\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  7,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]],\n",
       "\n",
       "        [[ 4, 10,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 2,  0,  1]],\n",
       "\n",
       "        [[ 5,  0,  6],\n",
       "         [ 0,  8,  0],\n",
       "         [ 3,  0,  9]]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.masked_fill(mask, value=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[[1, 1, 1],\n",
      "         [1, 1, 1],\n",
      "         [1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1],\n",
      "         [1, 1, 1],\n",
      "         [1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1],\n",
      "         [1, 1, 1],\n",
      "         [1, 1, 1]]])\n",
      "tensor([[[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "# ones(), zeros(), ones_like(), zeros_like()\n",
    "print(torch.ones(2,3))\n",
    "print(torch.zeros(2,3))\n",
    "print(torch.ones_like(x))\n",
    "print(torch.zeros_like(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
